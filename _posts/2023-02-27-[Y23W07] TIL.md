# [Y23W07] TIL

## Attention based Models

- 자연어 처리에서 Attention 기반의 Transformer모델이 RNN을 뛰어넘고 있음
- Transformer: self-attention을 바탕으로 각 시점 정보간의 관계를 모델링. CNN, RNN대비 long range dependency를 학습하기 용이
    - encoder - decoder 구조: encoder에는 앞단 신호 받아서 hidden representation(encoder output)생성한 수, decoder는 그 뒤의 신호+hidden representation받아서  decoding 수행.

## 시계열 예측연구의 대표적 challenge

- short vs long sequence time-series forecasting (LSTF).
    - long-range alignment ability → CNN, RNN대비 attention 메커니즘으로 transformer가 보완됨.
- efficient operation → quadratic한 연산속도. 문장길이가 길어지면 self attention 계산의 복잡도가 늘어난다.
    - sparse attention(bias 추가)

## DBSCAN

## DataScience 복습

- Confusion matrix (sklearn기준)
- 재현율=민감도 = Recall = Sensitivity: TP/(FN+TP)
    - 잼민이가 코로나 걸린사람 중 모델이 실제 코로나를 잘 예측할 확률

| 가로 predict, 세로 real | 0 | 1 |
| --- | --- | --- |
| 0 | TN | FP(1종오류) |
| 1 | FN | TP |
- F1 score: 2 / (1/recall + 1/precision),
- AUC그래프 x축 FPR, y축 TPR=recall
- 변동계수: 시그마 / 평균
- 정규성 판단 QQ-plot
- skew>0 (오른쪽 꼬리 분포) → 최빈, 중앙(짝수일때는 가운데 2개 평균), 평균 순서

## 이기적 실기

- 통계적 가설검정
    - 통계적 추측의 하나. 모집단의 실제 값이 얼마가 된다는 주장에 대해 표본의 정보를 사용해서 가설의 합당성 여부를 판정하는 과정.
    1. 유의수준 결정. 귀무가설, 대립가설 설정
        
        표본의 관찰을 통해 모집단은 ~~할 것이다. 귀무가설이 옳다는 가정하에 시작. 대립가설은 귀무가설이 기각될 때 받아들여지는 가설로 정의
        
    2. 검정통계량 설정
        
        가설을 검정하기 위한 기준으로 사용하는 값. 검정통계량이 확률분포 상 어디에 위치하는지에 따라 귀무가설 기각여부를 결정한다.
        
    3. 기각역의 설정
        
        확률분포에서 귀무가설을 기각하는 영역. 
        
    4. 검정통계량 계산: Z계산
        
        유의수준: 기각역들의 합. 1-신뢰수준. 
        
    5. 통계적 의사결정(가설검정)

---