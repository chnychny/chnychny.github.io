---
title: "This week I Learned 01"
excerpt: "[Y23W05] TIL"
date: 2023-02-05
categories: TIL
permalink: /categories/TIL/
tags: [3D_learning, 경제, ChatGPT, Attention, Transformer, Time_series_Deeplearning, MLOps, Posenet, OPIC]
---

### 3D learning의 장점?

- 3d cnn은 input layer가 4d tensor (depth, height, width, channel) 혹은 특성을 줄인 feature(I3D)로 학습하기도 한다. 나중에는 2D보다 좋아질 수 있겠다(point-level segmentation)
- 영상데이터 학습할때 원근법 때문에 이미지로 정확도가 떨어지는 부분이 존재함 → 물체의 위치가 뒤에 작을때 + 겹쳤을때, 또는 매우 세밀한 부분에서 분류가 필요할 때.
- AR, 자율주행,robotics 등 환경자체가 3 d인 어플리케이션들에게는 중요할듯
- 좀 더 실제와가까운 학습, 결과도출

### 3D learning for object detection | anomaly detection (classification)

- Data representation부터 다름
    - multiview: richly-annotated, large-scale repository (3dCAD model)
    - mesh: point + 관계(선)
    - volumetric: 3D modeling SW나 scan-net.org등으로 scene을 voxel labeling시킴
    - pointcloud: set of points (x,y,z,coordinate), LiDAR센서사용하거나 raw sensor meshdata변형
- 적용분야
    - Computer vision: 기존 2D로 하던 것들 전부 포함
    - 자율주행- obj detection & tracking  

- *_PointNet_* - point cloud(3차원 데이터 자체를 지칭)를 학습해 분류, 세그, 검출 가능 [16’, CVPR]
    - 기존의 Voxel화는 point cloud의 공간특성(요철)을 결손시킴
    - 꼭지점 인덱스의 순서에 대한 영향을 없앤다.
    - 한 파트에서 꼭지점 번호를 바꾸어도 똑같기 때문에 꼭지점을 재정렬한다.
        - augmentation을 그냥 하면 n개 꼭지점에 n!라 데이터 폭증→대칭함수사용해 모델구성.
        - 모든 꼭지점에 같은 가중치의 mlp를 걸거나, maxpooling을 사용해서 모든 꼭지점을 평등하게 다룬다.
    - 회전에 의한 영향을 없앤다.
        - T-Net을 쓴다 (3x3 transform을 수행. 변환행렬을 통과시켜서 회전영향 없앰)

## Time series Deep learning SOTA(state of the art)

- papers with code기준 여전히 GRU변형, MA_LSTM+FCN 계열이 1등하는중
    - GP-Sig-GRU → Bayesian learning from sequential data using Gaussian processes with signature covariance(2020, Tensorflow)
    - MALSTM-FCN → Multivariate LSTM-FCNs for Time series classification(2018, TimeseriesAI 에 pytorch지원)
- semi-supervised learing + multiscale attention + multi target contrast learning (bearing Fault Diagnosis)
- tsai(timeseries AI) : sota dl for timeseries and sequences. 파이토치라이브러리 (https://github.com/timeseriesAI/tsai)

## 23.02.01. TIL

    - 전후방산업
        - 전방산업: 용도가 특정되며 최종소비자에 가까운 산업
        - 후방산업: 원자재와 원료쪽에 가까운 산업
        - 자동차산업: 제조업의 꽃 (최종 전방산업인데 후방산업이랑 연관효과가 매우 큼. 고용 부가가치높)
    - 상계: 할부로 샀을 때, 매달 금액이 청구되면서 그 물건 금액만큼 차감되어 더이상 청구되지않으면 상계됐다고 표현함.
    - 종합소득세: 직접 신고해야함 (다음해 0501~0531)
        - 고용소득 외에 최근 5년 다른 소득이 있었다면? - 프리랜서, 알바, 부업이나 외주로 부수입, 원천징수 후 입금, 금융소득2천 초과
        - 이자/배당/사업/근로/연금/기타소득 → 종합과세 방식
        - 퇴직소득, 양도소득 → 분류과세 방식
    - AI생태계 - ChatGPT 생성형AI 분야 - from 미라클 레터  
    
    <img src="https://img.stibee.com/11584_1674981223.png" width="100">

        
    a) 직접 ai개발해서 앤드유저 앱까지 만드는 회사 (이전)  
    b) foundation model(초거대ai)를 폐쇄적으로 만드는회사(openAI, LG엑사원)
        - 초거대ai의 기초가 attention model  
    c) foundation model을 오픈소스로 만드는회사(stability AI:텍스트입력을 기반으로 이미지를 생성하는 개방형 AI도구 설계 및 구현 솔루션 제공, 네이버 하이퍼클로바, 카카오KoGPT)  
    d) b,c로부터 AI를 받아서 앤드유저용 제품만 만드는 회사(Github, 코파일럿)  
    e) 클라우드 인프라제공회사(AWS, MS, 구글, Naver Cloud, NHN클라우드, KT클라우드)  
    f) 클라우드 인프라 회사가 쓰는 AI반도체를 만드는 회사 (NVIDIA, 구글, AWS, 사피온, 퓨리오사AI, 리벨리온)

- 신성장동력: AI랑 같이 오는 로보틱스 (인체 보조로봇)
    - 인건비가 너무 높아. 위험한 작업. 작업시간 단축.
    - 인공지능을 탑재한 똑똑한 로봇, 저장되는 데이터는 빅데이터 클라우드가 됨.
    - 현재 한국 서빙로봇시장, 물류 무인운반로봇(AGV)은 중국이 장악.

## Attention model
- foundation model의 기초이자, 고장진단 포함 많은 분야에서 널리 활용되고 있음
- attention is all you need: parallel processing of words. 문장전체를 보는게 아니라 weight가 집중된 부분 정보만을 사용해서 output word를 예측함.
- 주어진 Query에 대해서 모든 Key와의 유사도를 각각 구한다. 이 유사도 가중치를 키와 연결되어있는 각각의 value에 반영해준다. value를 weighted sum해서 return
- self-attention - 참조: (https://aimb.tistory.com/182)
    - 쿼리 [단어에 대한 가중치]: 모든 시점(t가 계속 변하면서 반복적으로 쿼리를 수행하니까) 의 디코더 셀의 hidden states → 입력문장 모든 단어 벡터들
    - 키 [단어가 쿼리와 얼마나 연관되었는지 비교하는 가중치]: 모든 시점 인코더셀의 hidden states  → 입력문장 모든 단어 벡터들
    - value[의미에 대한 가중치]: 모든시점 인코더 셀의 hidden states  → 입력문장 모든 단어 벡터들
    - masked self-attention
        - decoding할때 타깃 단어 이후의 단어를 보지 않고 예측하기 위해서, 마스킹 처리하여 가리고 self-attention.
    - multi-head attention
        - scaled dot-product attention을 여러개의 head로 나누어 수행해, 병렬적으로 동시에 attention을 구하는 방법
        - one head가 어떤 한 단어가 다른 단어와 상호작용하는 정보를 뽑는다면, multi-head는 각 head별로 Q, K, V에 관한 self-attention을 수행함.
        - 파라미터 수를 줄이고, 다양한 정보를 파악가능
    
## Transformer model 
(aka. foundation model) - 출처: Nvidia blog.
- context를 학습해서 sequential data의 관계를 tracking하는 모델.
- attention, self-attention 구조가 많이 쓰인다.  
참조: [transformer구조설명](https://wikidocs.net/31379), [Multihead-attention](https://glanceyes.com/entry/Transformer%EC%9D%98-Multi-Head-Attention%EA%B3%BC-Transformer%EC%97%90%EC%84%9C-%EC%93%B0%EC%9D%B8-%EB%8B%A4%EC%96%91%ED%95%9C-%EA%B8%B0%EB%B2%95)
- large encoders-decoders 집단. 단어를 받는게 아니라 positional encoding으로 임베드+조정된 값을 입력으로 받음(단어순서).
- encoder: self attention (쿼리=키=밸류) 1개 + FF
- decoder: masked self attention(쿼리=키=밸류) + encoder의 결과물을 masked multihead (쿼리: 디코더, 키=밸류:인코더) + FF → linear + softmax  
- train data: text, image, speech, 3d signal…
- adaptation tasks: question answering, 감정분석, 정보추출, image captioning, 물체인식
- 성능면에서 이미 CNN, RNN들을 뛰어 넘었다. 하지만 계산량이 압도적으로 높은 것도 사실.
- transformer사용시 고려해야할 점:
    - self-attention에서 많은 양의 데이터와 연산량이 요구됨.
    - feature의 순서가 중요하지 않은경우, 데이터는 적은데 feature와 label은 많은 경우, sequence가 너무 긴경우 재고할 필요 있음
    - 그럼에도 불구하고 잘되는 이유?
        - sequence안의 각 token이 모든 다른 token을 참조함 (self-attention)
        - positional encoding때문에 sequence의 순서정보가 학습에 반영됨
    
### MLOps: Machine Learning Operation

- ML시스템 개발(Dev)과 ML시스템 운영(Ops)을 통합하는 것. 데이터 레이블링 일관성을 위해 인프라를 만들어 자동으로 운영되게끔 만드는 역할

1. Design
    - 산업의 요구를 바탕으로 문제정의하는 것. (예. 필요한 데이터, 어떤 딥러닝 기술이 좋을지)
    - 각 분야의 전문가적 지식 + 딥러닝적 학술지식(벤지오, 얀르쿤,..)
        - 좋은 ML모델을 고안하고 구현하는 건 너무 어렵고 자원이 많이 듦 → Neural Architecture Search(NAS) 기술이 연구되고 있음.
        - 혹은 기존 모델의 성능을 유지보수하고 빠른시간내에 향상시킨다 → 결국 좋은 데이터!(data-centric view! by 앤드류융)

2. Model development
    1. 디자인한 실험을 수행하기 위한 개발단계. 
    2. 매우 다양한 실험 필요
    3. pytorch, tf + 협업개발SW(github, VScode) — pytorch(lighting), fast.ai

3. Operation  
    1. 개발한 모델을 사용자에게 최종서비스
    2. 배포 장소에 따라 방식 달라짐(pc, 모바일 등)
    3. 지속적인 모니터링 요구됨(유지보수)
    4. 학계보다 주로 컴퓨터 엔지니어링 분야 
- 결국 1,2 를 잘해도 3이되지 않으면 거품.

### OPIC

- 일상의 모든 주제에 대해서 서론, 본론, 결론 1-2줄로 말하는 연습하기
- 오픽노잼
- 시제 및 단복수 주의

## PoseNet

- Posenet, Openpose로 skeleton 추출  
    skeleton data형태: heatmaps(움직임있는 점들) + offset vectors(keypoint위치)

## HOI(Human object interaction)
- HOI: 물체와 사람을 recognization하고 find triplet: [human, object, interaction]
- 라벨 = [사람, 물체, 앉았다]
- sequential HOI detector: 한 이미지에서 다 detect한 뒤에 interaction (iCAN, interactNet)
- parallel HOI detector: interaction구할때 NN인 sequential방식 대신 ROI(IoU, Interact box를 대신 사용) (PPDM), 휴리스틱 기준필요함.
- HOTR (HOI+transformer, CVPR2021) - DETR base, instance(recognize+interaction parallel decoder를 사용함.
    - video - CNN3d map 계산 - encoding - decoder (2개)
    - 한 개 이미지안에 interaction 수가 정해져 있지 않다 (라벨링 cost가 매우 큼) - hungarian losss algorithm사용.
